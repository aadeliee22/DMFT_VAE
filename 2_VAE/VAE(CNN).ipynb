{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.1'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import os.path as path\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '2'\n",
    "\n",
    "import lib.dist as dist\n",
    "import lib.utils as utils\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update({\n",
    "    'font.family' : 'STIXGeneral',\n",
    "    'mathtext.fontset' : 'stix', \n",
    "    'xtick.labelsize' : 13,\n",
    "    'xtick.top' : True,\n",
    "    'xtick.direction' : 'in',\n",
    "    'ytick.direction' : 'in',\n",
    "    'ytick.labelsize' : 13, \n",
    "    'ytick.right' : True, \n",
    "    'axes.labelsize' : 16,\n",
    "    'legend.frameon': False,\n",
    "    'legend.fontsize': 13,\n",
    "    'legend.handlelength' : 1.5,\n",
    "    'savefig.dpi' : 600,\n",
    "    'savefig.bbox' : 'tight'\n",
    "})\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt.shape = 3000 288\n"
     ]
    }
   ],
   "source": [
    "b = 60\n",
    "\n",
    "latent_dim = 8\n",
    "beta = 4\n",
    "prior_dist = dist.Normal()\n",
    "q_dist = dist.Normal()\n",
    "\n",
    "txt = np.loadtxt(f'../1_QMC/train/Bethe_14_beta{b:d}/field-2.10.dat')\n",
    "s_num, s_len = txt.shape\n",
    "print(\"txt.shape =\", s_num, s_len)\n",
    "s_train = 1000\n",
    "s_test = s_num-s_train\n",
    "if (s_train+s_test > s_num): print(\"WARNING : not enough datapoints\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "U = np.array([0.01*i for i in range(100, 401)])\n",
    "U_up, U_dn = [], []\n",
    "for i, u in enumerate(U):\n",
    "    if path.isfile(f'../1_QMC/train/Bethe_14_beta{b:d}/field-{u:.2f}.dat')==True: U_up.append(u)\n",
    "    if path.isfile(f'../1_QMC/train/Bethe_41_beta{b:d}/field-{u:.2f}.dat')==True: U_dn.append(u)\n",
    "U_up = np.array(U_up)\n",
    "U_dn = np.array(U_dn)\n",
    "\n",
    "#spin2d_up_train = np.zeros((len(U_up)*s_train, 1, 17, 17))\n",
    "#spin2d_dn_train = np.zeros((len(U_dn)*s_train, 1, 17, 17))\n",
    "spin2d_up_test = np.zeros((len(U_up)*s_test, 1, 17, 17))\n",
    "spin2d_dn_test = np.zeros((len(U_dn)*s_test, 1, 17, 17))\n",
    "print(\"U_up, U_dn len =\", len(U_up), len(U_dn))\n",
    "#print(\"spin2d_up_train size =\", spin2d_up_train.shape)\n",
    "#print(\"spin2d_dn_train size =\", spin2d_dn_train.shape)\n",
    "\n",
    "txt = np.zeros((s_num, s_len+1))\n",
    "for i, u in enumerate(U_up):\n",
    "    txt[:,:-1] = np.loadtxt(f'../1_QMC/train/Bethe_14_beta{b:d}/field-{u:.2f}.dat')\n",
    "    txt = 0.5*txt+0.5\n",
    "    #spin2d_up_train[i*s_train:(i+1)*s_train] = txt[:s_train,:].reshape(s_train, 1, 17, 17)\n",
    "    spin2d_up_test[i*s_test:(i+1)*s_test] = txt[-s_test:,:].reshape(s_test, 1, 17, 17)\n",
    "    spin2d_up[i*s_num:(i+1)*s_num] = txt.reshape(s_num, 1, 17, 17)\n",
    "for i, u in enumerate(U_dn):\n",
    "    txt[:,:-1] = np.loadtxt(f'../1_QMC/train/Bethe_41_beta{b:d}/field-{u:.2f}.dat')\n",
    "    txt = 0.5*txt+0.5\n",
    "    #spin2d_dn_train[i*s_train:(i+1)*s_train] = txt[:s_train,:].reshape(s_train, 1, 17, 17)\n",
    "    spin2d_dn_test[i*s_test:(i+1)*s_test] = txt[-s_test:,:].reshape(s_test, 1, 17, 17)\n",
    "    spin2d_dn[i*s_num:(i+1)*s_num] = txt.reshape(s_num, 1, 17, 17)\n",
    "\n",
    "\n",
    "spin2d = np.concatenate([spin2d_up, spin2d_dn])\n",
    "spin2d = torch.Tensor(spin2d)\n",
    "print(\"spin2d size =\", spin2d.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CEncoder(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        super(CEncoder, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        #self.conv1 = nn.Conv2d(1, 16, 4, 2, 1)  # 16\n",
    "        #self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(1, 16, 5, 2, 1)  # 8\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 4, 2, 1)  # 4\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.conv4 = nn.Conv2d(32, 256, 4)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.conv_z = nn.Conv2d(256, output_dim, 1)\n",
    "\n",
    "        # setup the non-linearity\n",
    "        self.act = nn.SELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = x.view(-1, 1, 17, 17)\n",
    "        #h = self.act(self.bn1(self.conv1(h)))\n",
    "        h = self.act(self.bn2(self.conv2(h)))\n",
    "        h = self.act(self.bn3(self.conv3(h)))\n",
    "        h = self.act(self.bn4(self.conv4(h)))\n",
    "        z = self.conv_z(h).view(x.size(0), self.output_dim)\n",
    "        return z\n",
    "    \n",
    "class CDecoder(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(CDecoder, self).__init__()\n",
    "        self.conv1 = nn.ConvTranspose2d(input_dim, 256, 1, 1, 0)  # 1 x 1\n",
    "        self.bn1 = nn.BatchNorm2d(256)\n",
    "        self.conv2 = nn.ConvTranspose2d(256, 32, 4, 1, 0)  # 4\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.ConvTranspose2d(32, 16, 4, 2, 1)  # 8\n",
    "        self.bn3 = nn.BatchNorm2d(16)\n",
    "        #self.conv4 = nn.ConvTranspose2d(16, 16, 4, 2, 1)  # 16\n",
    "        #self.bn4 = nn.BatchNorm2d(16)\n",
    "        self.conv_final = nn.ConvTranspose2d(16, 1, 5, 2, 1) #17\n",
    "\n",
    "        # setup the non-linearity\n",
    "        self.act = nn.SELU()\n",
    "\n",
    "    def forward(self, z):\n",
    "        h = z.view(z.size(0), z.size(1), 1, 1)\n",
    "        h = self.act(self.bn1(self.conv1(h)))\n",
    "        h = self.act(self.bn2(self.conv2(h)))\n",
    "        h = self.act(self.bn3(self.conv3(h)))\n",
    "        #h = self.act(self.bn4(self.conv4(h)))\n",
    "        mu_img = self.conv_final(h)\n",
    "        return mu_img\n",
    "    \n",
    "def logsumexp(value, dim=None, keepdim=False):\n",
    "    \"\"\"Numerically stable implementation of the operation\n",
    "    value.exp().sum(dim, keepdim).log()\n",
    "    \"\"\"\n",
    "    if dim is not None:\n",
    "        m, _ = torch.max(value, dim=dim, keepdim=True)\n",
    "        value0 = value - m\n",
    "        if keepdim is False:\n",
    "            m = m.squeeze(dim)\n",
    "        return m + torch.log(torch.sum(torch.exp(value0),\n",
    "                                       dim=dim, keepdim=keepdim))\n",
    "    else:\n",
    "        m = torch.max(value)\n",
    "        sum_exp = torch.sum(torch.exp(value - m))\n",
    "        if isinstance(sum_exp, Number):\n",
    "            return m + math.log(sum_exp)\n",
    "        else:\n",
    "            return m + torch.log(sum_exp)\n",
    "        \n",
    "def display_samples(model, x):\n",
    "    fig, ax = plt.subplots(1,2, figsize = (15, 3))\n",
    "    th = 1\n",
    "    sample_mu = model.model_sample(batch_size=100).sigmoid()\n",
    "    xs, x_params, zs, z_params = model.reconstruct_img(x)\n",
    "    ax[0].imshow(x[th,0], aspect='auto')\n",
    "    ax[1].imshow(xs[th,0], aspect='auto')\n",
    "    #ax[2].imshow(x_params[th,0].detach().numpy())\n",
    "    #ax[3].imshow(z_params[:,:,0].detach().numpy())\n",
    "    #ax[4].imshow(z_params[:,:,1].detach().numpy())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### beta-TCVAE\n",
    "class TCVAE(nn.Module):\n",
    "    def __init__(self, z_dim, beta, prior_dist=dist.Normal(), q_dist=dist.Normal(),\n",
    "                 include_mutinfo=True, tcvae=True, mss=True):\n",
    "        super(TCVAE, self).__init__()\n",
    "        \n",
    "        self.z_dim = z_dim\n",
    "        self.include_mutinfo = include_mutinfo\n",
    "        self.tcvae = tcvae\n",
    "        self.lamb = 0\n",
    "        self.beta = beta\n",
    "        self.mss = mss\n",
    "        self.x_dist = dist.Bernoulli()\n",
    "\n",
    "        self.prior_dist = prior_dist\n",
    "        self.q_dist = q_dist\n",
    "        self.register_buffer('prior_params', torch.zeros(self.z_dim, 2))\n",
    "\n",
    "        self.encoder = CEncoder(z_dim * self.q_dist.nparams)\n",
    "        self.decoder = CDecoder(z_dim)\n",
    "\n",
    "    def _get_prior_params(self, batch_size=1):\n",
    "        expanded_size = (batch_size,) + self.prior_params.size()\n",
    "        prior_params = Variable(self.prior_params.expand(expanded_size))\n",
    "        return prior_params\n",
    "    \n",
    "    def model_sample(self, batch_size=1):\n",
    "        prior_params = self._get_prior_params(batch_size)\n",
    "        zs = self.prior_dist.sample(params=prior_params)\n",
    "        x_params = self.decoder.forward(zs)\n",
    "        return x_params\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = x.view(x.size(0), 1, 17, 17)\n",
    "        z_params = self.encoder.forward(x).view(x.size(0), self.z_dim, self.q_dist.nparams)\n",
    "        zs = self.q_dist.sample(params=z_params)\n",
    "        return zs, z_params\n",
    "\n",
    "    def decode(self, z):\n",
    "        x_params = self.decoder.forward(z).view(z.size(0), 1, 17, 17)\n",
    "        xs = self.x_dist.sample(params=x_params)\n",
    "        return xs, x_params\n",
    "\n",
    "    def reconstruct_img(self, x):\n",
    "        zs, z_params = self.encode(x)\n",
    "        xs, x_params = self.decode(zs)\n",
    "        return xs, x_params, zs, z_params\n",
    "    \n",
    "    def _log_importance_weight_matrix(self, batch_size, dataset_size):\n",
    "        N = dataset_size\n",
    "        M = batch_size - 1\n",
    "        strat_weight = (N - M) / (N * M)\n",
    "        W = torch.Tensor(batch_size, batch_size).fill_(1 / M)\n",
    "        W.view(-1)[::M+1] = 1 / N\n",
    "        W.view(-1)[1::M+1] = strat_weight\n",
    "        W[M-1, 0] = strat_weight\n",
    "        return W.log()\n",
    "    \n",
    "    def elbo(self, x, dataset_size):\n",
    "        batch_size = x.size(0) \n",
    "        x = x.view(batch_size, 1, 17, 17)\n",
    "        prior_params = self._get_prior_params(batch_size)\n",
    "        x_recon, x_params, zs, z_params = self.reconstruct_img(x)\n",
    "        logpx = self.x_dist.log_density(x, params=x_params).view(batch_size, -1).sum(1)\n",
    "        logpz = self.prior_dist.log_density(zs, params=prior_params).view(batch_size, -1).sum(1)\n",
    "        logqz_condx = self.q_dist.log_density(zs, params=z_params).view(batch_size, -1).sum(1) \n",
    "\n",
    "        elbo = logpx + logpz - logqz_condx # log p(x|z) + log p(z) - log q(z|x)\n",
    "        # log q(z) ~ log 1/(NM) sum_m=1^M q(z|x_m) = - log(MN) + logsumexp_m(q(z|x_m))\n",
    "        _logqz = self.q_dist.log_density(zs.view(batch_size, 1, self.z_dim),\n",
    "                                         z_params.view(1, batch_size, self.z_dim, self.q_dist.nparams))\n",
    "\n",
    "        if not self.mss: # minibatch weighted sampling\n",
    "            logqz_prodmarginals = (logsumexp(_logqz, dim=1, keepdim=False) - math.log(batch_size * dataset_size)).sum(1)\n",
    "            logqz = (logsumexp(_logqz.sum(2), dim=1, keepdim=False) - math.log(batch_size * dataset_size))\n",
    "        else: # minibatch stratified sampling\n",
    "            logiw_matrix = Variable(self._log_importance_weight_matrix(batch_size, dataset_size).type_as(_logqz.data))\n",
    "            logqz = logsumexp(logiw_matrix + _logqz.sum(2), dim=1, keepdim=False)\n",
    "            logqz_prodmarginals = logsumexp(\n",
    "                logiw_matrix.view(batch_size, batch_size, 1) + _logqz, dim=1, keepdim=False).sum(1)\n",
    "\n",
    "        if self.include_mutinfo:\n",
    "            elbo2 = logpx - logqz_condx + logqz - self.beta * (logqz - logqz_prodmarginals) - \\\n",
    "                                (1 - self.lamb) * (logqz_prodmarginals - logpz)\n",
    "        else:\n",
    "            elbo2 = logpx - self.beta * (logqz - logqz_prodmarginals) - \\\n",
    "                                (1 - self.lamb) * (logqz_prodmarginals - logpz)\n",
    "\n",
    "        return elbo2, elbo.detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if previous_model == True:\n",
    "    model = TCVAE(z_dim=latent_dim, beta=beta, prior_dist=prior_dist, q_dist=q_dist)\n",
    "    model.load_state_dict(torch.load('./frozen/VAE_CNN_2.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if previous_model == False:\n",
    "    model = TCVAE(z_dim=latent_dim, beta=beta, prior_dist=prior_dist, q_dist=q_dist)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    train_loader=DataLoader(dataset=spin2d, batch_size=1000, shuffle=True)\n",
    "\n",
    "    train_elbo = []\n",
    "    dataset_size = len(train_loader.dataset)\n",
    "    num_iter = len(train_loader)*100\n",
    "    print(\"dataset_size, num_iter =\", dataset_size, num_iter)\n",
    "    elbo_run_mean = utils.RunningAverageMeter()\n",
    "\n",
    "    for n in range(num_iter):\n",
    "        for i,x in enumerate(train_loader):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            obj, elbo = model.elbo(x, dataset_size)\n",
    "            if utils.isnan(obj).any(): break\n",
    "            obj.mean().mul(-1).backward()\n",
    "            elbo_run_mean.update(elbo.mean().item())\n",
    "            optimizer.step()\n",
    "\n",
    "        if n%50==0:\n",
    "            train_elbo.append(elbo_run_mean.avg)\n",
    "            print('[n = %03d] ELBO = %.6f (%.6f)'%(n, elbo_run_mean.val, elbo_run_mean.avg))\n",
    "            display_samples(model, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spin2dtest = np.concatenate([spin2d_up_test, spin2d_dn_test])\n",
    "spin2dtest = torch.Tensor(spin2dtest)\n",
    "xs, x_params, zs, z_params = model.reconstruct_img(spin2dtest)\n",
    "\n",
    "test_mu = z_params[:, :, 0].detach().numpy()\n",
    "test_logsig = z_params[:, :, 1].detach().numpy()\n",
    "test_var = np.exp(test_logsig * 2)\n",
    "fig, ax = plt.subplots(1,2, figsize = (6, 6))\n",
    "ax[0].imshow(test_mu, aspect = 'auto')\n",
    "ax[1].imshow(test_var, aspect = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_len = len(U_up)+len(U_dn)\n",
    "spin2d_up_test = torch.Tensor(spin2d_up_test)\n",
    "spin2d_dn_test = torch.Tensor(spin2d_dn_test)\n",
    "#xs, x_params, zs, z_params = model.reconstruct_img(spin2dtest)\n",
    "#xs_up, x_params_up, zs_up, z_params_up = model.reconstruct_img(spin2d_up_test)\n",
    "#xs_dn, x_params_dn, zs_dn, z_params_dn = model.reconstruct_img(spin2d_dn_test)\n",
    "\n",
    "plt.imshow(spin2dtest.reshape(U_len*s_test, 289), aspect='auto')\n",
    "cd = plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(xs.reshape(U_len*s_test, 289), aspect='auto')\n",
    "cd = plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ens_mu = np.zeros((134, latent_dim))\n",
    "test_ens_logsig = np.zeros((134, latent_dim))\n",
    "for i in range(134):\n",
    "    test_ens_mu[i] = np.average(z_params[i*s_test:(i+1)*s_test, :, 0].detach().numpy(), axis=0)\n",
    "    test_ens_logsig[i] = np.average(z_params[i*s_test:(i+1)*s_test, :, 1].detach().numpy(), axis=0)\n",
    "test_ens_var = np.exp(test_ens_logsig * 2)\n",
    "fig, ax = plt.subplots(1,2, figsize = (6, 6))\n",
    "ax[0].imshow(test_ens_mu, aspect = 'auto')\n",
    "ax[1].imshow(test_ens_var, aspect = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if previous_model == False: torch.save(model.state_dict(), 'frozen/VAE_CNN_1.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler1 = StandardScaler()\n",
    "#scaler1.fit(test_mu)\n",
    "#mu_scaled = scaler1.transform(test_mu)\n",
    "pca1 = PCA(n_components=3)\n",
    "pca1.fit(test_ens_mu)\n",
    "mu_pca = pca1.transform(test_ens_mu)\n",
    "\n",
    "#scaler2 = StandardScaler()\n",
    "#scaler2.fit(test_var)\n",
    "#var_scaled = scaler2.transform(test_var)\n",
    "pca2 = PCA(n_components=2)\n",
    "pca2.fit(test_ens_var)\n",
    "var_pca = pca2.transform(test_ens_var)\n",
    "\n",
    "UU = np.concatenate([U_up, U_dn])\n",
    "\n",
    "plt.plot(UU, mu_pca[:,0], 'b.-')\n",
    "plt.plot(UU, mu_pca[:,1], 'r.-')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(UU, var_pca[:,0], 'b.-')\n",
    "plt.plot(UU, var_pca[:,1], 'r.-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"### VAE\n",
    "cCh=16\n",
    "ksize=7\n",
    "fD=cCh*2*20*20\n",
    "zD=16\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, imgCh=1): # 7: 32-26-20, 5: 32-28-24\n",
    "        super().__init__()\n",
    "    \n",
    "        self.eC1 = nn.Conv2d(imgCh, cCh, kernel_size = ksize)\n",
    "        self.eC2 = nn.Conv2d(cCh, cCh*2, kernel_size = ksize)\n",
    "        self.eL1 = nn.Linear(fD, zD) \n",
    "        self.eL2 = nn.Linear(fD, zD)\n",
    "    \n",
    "        self.dL1 = nn.Linear(zD, fD)\n",
    "        self.dC1 = nn.ConvTranspose2d(cCh*2, cCh, ksize)\n",
    "        self.dC2 = nn.ConvTranspose2d(cCh, imgCh, ksize)\n",
    "    \n",
    "        self.actv = nn.SELU()\n",
    "        self.Sigm = torch.Sigmoid()\n",
    "    \n",
    "    def encoder(self, x):\n",
    "        x = self.actv(self.eC1(x))\n",
    "        x = self.actv(self.eC2(x))\n",
    "        x = x.view(-1, fD)\n",
    "        mu = self.eL1(x)\n",
    "        logvar = self.eL2(x)\n",
    "        return mu, logvar\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(logvar/2)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + std * eps\n",
    "    \n",
    "    def decoder(self, z):\n",
    "        x = self.actv(self.dL1(z))\n",
    "        x = x.view(-1, cCh*2, 20, 20)\n",
    "        x = self.actv(self.dC1(x))\n",
    "        x = self.Sigm(self.dC2(x))\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        out = self.decoder(z)\n",
    "        return out, mu, logvar\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 60 #inverse temp\n",
    "\n",
    "U = np.array([0.01*i for i in range(100, 401)])\n",
    "U_up, U_dn = [], []\n",
    "for i, u in enumerate(U):\n",
    "    if path.isfile(f'../1_QMC/train/Bethe_14_beta{b:d}/Gtau-{u:.2f}.dat')==True: U_up.append(u)\n",
    "    if path.isfile(f'../1_QMC/train/Bethe_41_beta{b:d}/Gtau-{u:.2f}.dat')==True: U_dn.append(u)\n",
    "U_up = np.array(U_up)\n",
    "U_dn = np.array(U_dn)\n",
    "spin2d = np.arange((len(U_up)+len(U_dn))*289)\n",
    "spin2d = spin2d.reshape((len(U_up)+len(U_dn)), 1, 17, 17)\n",
    "\n",
    "txt = np.zeros(289)\n",
    "for i, u in enumerate(U_up):\n",
    "    txt[:-1] = np.loadtxt(f'../1_QMC/train/Bethe_14_beta{b:d}/field-{u:.2f}.dat')\n",
    "    spin2d[i] = txt.reshape(1, 1, 17, 17)\n",
    "for i, u in enumerate(U_dn):\n",
    "    txt[:-1] = np.loadtxt(f'../1_QMC/train/Bethe_41_beta{b:d}/field-{u:.2f}.dat')\n",
    "    spin2d[len(U_up)+i] = txt.reshape(1, 1, 17, 17)\n",
    "\n",
    "latent_dim = 4\n",
    "beta = 4\n",
    "prior_dist = dist.Normal()\n",
    "q_dist = dist.Normal()\n",
    "\n",
    "\n",
    "spin2d = torch.Tensor(spin2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2 = nn.Conv2d(1, 16, 5, 2, 1)  # 8\n",
    "bn2 = nn.BatchNorm2d(16)\n",
    "conv3 = nn.Conv2d(16, 32, 4, 2, 1)  # 4\n",
    "bn3 = nn.BatchNorm2d(32)\n",
    "conv4 = nn.Conv2d(32, 256, 4)\n",
    "bn4 = nn.BatchNorm2d(256)\n",
    "conv_z = nn.Conv2d(256, 8, 1)\n",
    "act = nn.SELU()\n",
    "\n",
    "h = spin2d.view(-1, 1, 17, 17)\n",
    "h = act(bn2(conv2(h)))\n",
    "print(h.shape)\n",
    "h.shape\n",
    "h = act(bn3(conv3(h)))\n",
    "h.shape\n",
    "h = act(bn4(conv4(h)))\n",
    "z = conv_z(h).view(spin2d.size(0), 8)\n",
    "zp = z.view(spin2d.size(0), 4, 2)\n",
    "zs = dist.Normal().sample(params=zp)\n",
    "print(z.shape, zp.shape, zs.shape)\n",
    "\n",
    "conv1 = nn.ConvTranspose2d(4, 256, 1, 1, 0)  # 1 x 1\n",
    "bn1 = nn.BatchNorm2d(256)\n",
    "conv2 = nn.ConvTranspose2d(256, 32, 4, 1, 0)  # 4\n",
    "bn2 = nn.BatchNorm2d(32)\n",
    "conv3 = nn.ConvTranspose2d(32, 16, 4, 2, 1)  # 8\n",
    "bn3 = nn.BatchNorm2d(16)\n",
    "conv_final = nn.ConvTranspose2d(16, 1, 5, 2, 1) #17\n",
    "act = nn.SELU()\n",
    "\n",
    "h = zs.view(zs.size(0), zs.size(1), 1, 1)\n",
    "h = act(bn1(conv1(h)))\n",
    "h = act(bn2(conv2(h)))\n",
    "h = act(bn3(conv3(h)))\n",
    "mu_img = conv_final(h)\n",
    "mu_img.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
